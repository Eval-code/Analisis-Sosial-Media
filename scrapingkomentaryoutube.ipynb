{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaLKV0/pTEniocbgPmY12+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eval-code/Analisis-Sosial-Media/blob/main/scrapingkomentaryoutube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL GOGLE API"
      ],
      "metadata": {
        "id": "7NQYsw8EPpXr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gjplyv6_IJIZ",
        "outputId": "2efac0bb-57a1-47c4-a619-021050cdb259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (2.182.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "pip install google-api-python-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNGSI KUNCI API ANDA"
      ],
      "metadata": {
        "id": "d8MqQoezP5o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def_api_key = 'AIzaSyCgu2z5xO41jfIXmNixLq3vaxBQGet_3gQ'"
      ],
      "metadata": {
        "id": "UGIPkTI6JaG9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TY6SFd8dP2mD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTSALL PUSTAKA YANG DIPERLUKAN"
      ],
      "metadata": {
        "id": "DHdyIy04P7gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "SMv4q2YwJo6d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KODE SCRAPPING KOMENTAR YOUTUBE"
      ],
      "metadata": {
        "id": "XWzOzSMYP-6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Asumsi: Anda sudah mendefinisikan def_api_key dan fungsi build\n",
        "# Inisialisasi layanan YouTube API\n",
        "youtube = build('youtube', 'v3', developerKey=def_api_key)\n",
        "\n",
        "\n",
        "video_id = 'd6ERxFyOkiI'\n",
        "\n",
        "def get_comments(video_id, max_comments=1000):\n",
        "    \"\"\"\n",
        "    Mengambil komentar dari video YouTube dengan batasan jumlah total komentar.\n",
        "\n",
        "    video_id (str): ID video target.\n",
        "    max_comments (int): Jumlah maksimum komentar (utama + balasan) yang ingin diambil.\n",
        "    \"\"\"\n",
        "    comments = []\n",
        "\n",
        "    # maxResults per halaman diatur ke 100 (maksimum API)\n",
        "    page_size = 100\n",
        "\n",
        "    request = youtube.commentThreads().list(\n",
        "        part='snippet,replies',\n",
        "        videoId=video_id,\n",
        "        maxResults=page_size,\n",
        "        textFormat='plainText'\n",
        "    )\n",
        "\n",
        "    while request and len(comments) < max_comments:\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            # 1. Ambil Komentar Utama (Top Level Comment)\n",
        "            if len(comments) >= max_comments:\n",
        "                break # Hentikan jika sudah mencapai batas\n",
        "\n",
        "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
        "            comments.append({\n",
        "                'author': top_comment['authorDisplayName'],\n",
        "                'comment': top_comment['textDisplay'],\n",
        "                'likes': top_comment['likeCount'],\n",
        "            })\n",
        "\n",
        "            # 2. Ambil Balasan (Replies)\n",
        "            if 'replies' in item:\n",
        "                for reply in item['replies']['comments']:\n",
        "                    if len(comments) >= max_comments:\n",
        "                        break # Hentikan jika sudah mencapai batas\n",
        "\n",
        "                    reply_snippet = reply['snippet']\n",
        "                    comments.append({\n",
        "                        'author': reply_snippet['authorDisplayName'],\n",
        "                        'comment': reply_snippet['textDisplay'],\n",
        "                        'likes': reply_snippet['likeCount'],\n",
        "                        'is_reply': True\n",
        "                    })\n",
        "\n",
        "        # Pindah ke halaman berikutnya\n",
        "        request = youtube.commentThreads().list_next(request, response)\n",
        "\n",
        "    # Pastikan kita hanya mengembalikan sebanyak max_comments\n",
        "    return comments[:max_comments]\n",
        "\n",
        "# --- PENGGUNAAN ---\n",
        "# Mengambil tergantung user komentar saja\n",
        "all_comments = get_comments(video_id, max_comments=10)\n",
        "\n",
        "# Simpan ke DataFrame\n",
        "df = pd.DataFrame(all_comments)\n",
        "\n",
        "print(f\"Total komentar yang diambil: {len(df)}\")\n",
        "print(df.head())\n",
        "df.to_excel('comments.xlsx', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-A_8S21tOfsy",
        "outputId": "4db59732-2dd8-4d22-90de-d1d233e06298"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total komentar yang diambil: 10\n",
            "                    author                                            comment  \\\n",
            "0            @RizkyNew-j9e                                Ndx seribu kenangan   \n",
            "1  @noviaryantimulyana6295                                             mantap   \n",
            "2        @raynanabilla5040                                             mantap   \n",
            "3       @Cintadeswanahunta  Aku sama kakakku suka banget lagu jawa apa lag...   \n",
            "4            @bakdiyah8108                                                 ❤k   \n",
            "\n",
            "   likes  \n",
            "0      0  \n",
            "1      0  \n",
            "2      0  \n",
            "3      0  \n",
            "4      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOKENISASI KALIMAT DAN KATA"
      ],
      "metadata": {
        "id": "tkJbkml0YmTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# --- pastikan NLTK punya data tokenizer ---\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# --- Download the missing resource ---\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# --- load komentar ---\n",
        "df = pd.read_excel(\"comments.xlsx\")\n",
        "comments = df[\"comment\"].tolist()\n",
        "\n",
        "# --- fungsi tokenisasi ---\n",
        "def tokenize_sentences(text):\n",
        "    return nltk.sent_tokenize(text)\n",
        "\n",
        "def tokenize_words(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^0-9a-zA-ZáéíóúÁÉÍÓÚâêîôûäëïöüğşçñ_-]', ' ', text)  # bersihkan tanda baca\n",
        "    return [t for t in text.split() if t.strip()]\n",
        "\n",
        "# --- lakukan tokenisasi ---\n",
        "results = []\n",
        "for idx, comment in enumerate(comments, 1):\n",
        "    sentences = tokenize_sentences(comment)\n",
        "    words = tokenize_words(comment)\n",
        "    results.append({\n",
        "        \"id\": idx,\n",
        "        \"original\": comment,\n",
        "        \"sentences\": sentences,\n",
        "        \"words\": words\n",
        "    })\n",
        "\n",
        "# --- tampilkan contoh hasil ---\n",
        "for r in results:\n",
        "    print(f\"\\nKomentar {r['id']}: {r['original']}\")\n",
        "    print(f\"  Kalimat : {r['sentences']}\")\n",
        "    print(f\"  Kata    : {r['words']}\")\n",
        "\n",
        "# --- simpan ke file CSV ---\n",
        "flat_data = []\n",
        "for r in results:\n",
        "    flat_data.append({\n",
        "        \"id\": r[\"id\"],\n",
        "        \"original\": r[\"original\"],\n",
        "        \"sentences\": \" || \".join(r[\"sentences\"]),\n",
        "        \"words\": \" \".join(r[\"words\"])\n",
        "    })\n",
        "\n",
        "out = pd.DataFrame(flat_data)\n",
        "out.to_csv(\"tokenized_comments.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"\\nHasil tokenisasi disimpan ke 'tokenized_comments.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmOKdw-BWQaZ",
        "outputId": "27c16ed9-9dcc-4e8f-8168-d11a1b36b378"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Komentar 1: Ndx seribu kenangan\n",
            "  Kalimat : ['Ndx seribu kenangan']\n",
            "  Kata    : ['ndx', 'seribu', 'kenangan']\n",
            "\n",
            "Komentar 2: mantap\n",
            "  Kalimat : ['mantap']\n",
            "  Kata    : ['mantap']\n",
            "\n",
            "Komentar 3: mantap\n",
            "  Kalimat : ['mantap']\n",
            "  Kata    : ['mantap']\n",
            "\n",
            "Komentar 4: Aku sama kakakku suka banget lagu jawa apa lagi lagu nemen bagus banget\n",
            "  Kalimat : ['Aku sama kakakku suka banget lagu jawa apa lagi lagu nemen bagus banget']\n",
            "  Kata    : ['aku', 'sama', 'kakakku', 'suka', 'banget', 'lagu', 'jawa', 'apa', 'lagi', 'lagu', 'nemen', 'bagus', 'banget']\n",
            "\n",
            "Komentar 5: ❤k\n",
            "  Kalimat : ['❤k']\n",
            "  Kata    : ['k']\n",
            "\n",
            "Komentar 6: ❤\n",
            "  Kalimat : ['❤']\n",
            "  Kata    : []\n",
            "\n",
            "Komentar 7: Redmi pad 1 ada fiturnya tp wkt dicari di windowsnya no display available.\n",
            "  Kalimat : ['Redmi pad 1 ada fiturnya tp wkt dicari di windowsnya no display available.']\n",
            "  Kata    : ['redmi', 'pad', '1', 'ada', 'fiturnya', 'tp', 'wkt', 'dicari', 'di', 'windowsnya', 'no', 'display', 'available']\n",
            "\n",
            "Komentar 8: good luck walaupun tidak mengerti dengan bahasa jawanya\n",
            "  Kalimat : ['good luck walaupun tidak mengerti dengan bahasa jawanya']\n",
            "  Kata    : ['good', 'luck', 'walaupun', 'tidak', 'mengerti', 'dengan', 'bahasa', 'jawanya']\n",
            "\n",
            "Komentar 9: 😢 😢😢\n",
            "  Kalimat : ['😢 😢😢']\n",
            "  Kata    : []\n",
            "\n",
            "Komentar 10: lagu ke ini hampir semua lirik ny sy hafal😂\n",
            "  Kalimat : ['lagu ke ini hampir semua lirik ny sy hafal😂']\n",
            "  Kata    : ['lagu', 'ke', 'ini', 'hampir', 'semua', 'lirik', 'ny', 'sy', 'hafal']\n",
            "\n",
            "Hasil tokenisasi disimpan ke 'tokenized_comments.csv'\n"
          ]
        }
      ]
    }
  ]
}